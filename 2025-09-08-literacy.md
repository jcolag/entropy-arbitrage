---
layout: post
title: Developer Diary, International Literacy Day
date: 2025-09-08 07:05:05-0400
categories:
tags: [programming, project, dev-journal]
summary: Progress on assorted projects
thumbnail: /blog/assets/fountain-pen-writing-literacy.png
offset: -30%
description: This week's projects include social media-ish changes, a Codidact answer, a home-server addition, the Ham newsletter generator, the blog's code, Boring CSS, Bicker, Open Badges, and my Mastodon Tool Trunk.
spell: Codidact Ollama cUrl Dilworthy boring-css Petar Milošević
proofed: true
---

* Ignore for ToC
{:toc}

Today marks [International Literacy Day](https://en.wikipedia.org/wiki/International_Literacy_Day), aiming to highlight the importance of reading, increasingly on a societal level.  Around one in five adults currently can't read, with regional illiteracy rates ranging from Burkina Faso's 12.8% to South Asia's 58.6%, correlating strongly with both poverty and misogyny, for reasons that we can probably all guess.

![The nib of a fountain pen hovering above Cyrillic writing](/blog/assets/fountain-pen-writing-literacy.png "I should probably go to the trouble of confirming that the text doesn't say anything horrible instead of only quickly sounding it out, but...")

With that, on to the week's projects.

## Social Media

Well, this sits more adjacent to social media, I guess.

Have you thought to yourself that you'd love to throw money at me, but on principle refuse to do it without some decentralized layer involved?  Well, you can now [support me on Crowd Bucks](https://crowdbucks.fund/@jcolag@mastodon.social), which as the URL suggests, uses Mastodon---with plans to use other Fediverse systems soon---to log in.  They also plan federation for themselves, soon.

While I doubt that I had any influence on this project, I should note that, since it really only provides a transaction monitoring layer over Stripe at the moment, I do want to note how similar Crowd Bucks looks to my pitch for a [politics-resistant payment processor]({% post_url 2025-07-27-payment-processor %}) from a month or two back.  I haven't [investigated the internals](https://codeberg.org/crowdbucks), but it looks like it mostly only forwards your payment request to Stripe as the payment processor, which doesn't *quite* solve the entire problem, but puts a nicer face on the remaining steps, I think.

### Process

For those of you who don't want excuses to throw money at me---shocking a concept as that might sound to many[^1] of you---and would rather I serve as the "early adopter" so that you can sign up in relative safety, I can tell you what I know from signing up.

[^1]:  I mean "many" in the most liberal sense of the word, here, as in "probably nobody."

- Signing up for Crowd Bucks looks exactly like what you'd expect.  You supply your server and handle from the Fediverse (Mastodon only, at the moment), then approve the connection from your Fediverse instance.
- Connect Stripe.  When I first tried out Crowd Bucks a couple of weeks ago, it had some bugs in its own Stripe setup, passing along mystifying errors suggesting that I needed to set myself up as a payment processor.  But when I tried again during the week, it went through, using the same "store" that I use for my [Bookshop.org store](https://bookshop.org/shop/entropy) that I've let fall out of date.
- It then provides a profile URL, [`https://crowdbucks.fund/` plus your Fediverse ID](https://crowdbucks.fund/@jcolag@mastodon.social) to share.
- People start throwing money...at least in theory.

They treat Stripe as optional, and I don't know what happens to funds if you don't set it up.  I would *guess* that you can move the money around internally, supporting your own favorite creators, but I didn't investigate or ask.

### Caveats

Do I have misgivings about people trying to monetize the Fediverse?  Sure.  But like I said in my post about (hypothetically) building a payment processor, and even before that when I talked about the high [value of federated services]({% post_url 2023-04-23-federation %}), once Crowd Bucks gets its Activity Pub code working, a project like this will create a scheme where it finds a nice tradeoff between ease of accepting payments and difficulty of somebody imposing their will on who has permission to monetize their work.  You don't need to have every artist also become a system administrator, and nobody can threaten to cut off or buy *every* instance, when another can always spring up somewhere else.

And yes, terrible people will use this, too.  I don't like that, and presumably neither do you.  But I also adhere strongly to [Blackstone's ratio](https://en.wikipedia.org/wiki/Blackstone%27s_ratio) in a lot of cases, that I'd rather many terrible persons escape than that one innocent suffer.  I tend to prefer Benjamin Franklin's restatement of the ratio using a hundred offenders instead of Blackstone's ten, but the principle doesn't change.

## Codidact

This week, rather close to my heart after years of managing this blog, I answered [What are best practices for keeping my blog in version control repository](https://powerusers.codidact.com/posts/294557/294563#answer-294563), where I outlined the three repositories that I use for this blog---[code](https://codeberg.org/jcolag/entropy-arbitrage-code), [posts](https://codeberg.org/jcolag/entropy-arbitrage-posts), and [assets](https://gitlab.com/jcolag/entropy-arbitrage-assets), for those of you not familiar with how I do this---and why I set it up that way.  They needed ideas for WordPress, but with an export scheme, their setup shouldn't look *too* different from a Jekyll scheme.

## Mini-Server, Part 9

This may come to nothing, in the end, but for the sake of completeness, I should mention that I installed [Ollama](https://ollama.com/) on the now-spare-again laptop.

I know.  An LLM in *my* house.  But hear me out.

Generative AI, in my eyes, has three problems, four if you include the massive bubble that might tank the economy when it bursts.

- Large models live in data centers, wasting energy and water.
- Training has scarfed down data without consent, making reuse of its output troubling.
- They (definitionally) don't care about any tasks, but chatbots try to give the impression that they do nothing but care.

By contrast, my ancient laptop can't handle anything but the tiniest models, making this relatively clean, and I don't care about the chat interface or producing "content" to use, especially given the low-power models.

### Why Do This

What might I do with this setup?  For my first test-case, I sent it a message over the API instructing the model to take the accompanying text---one of my own short stories---and return a JSON array containing the name and a brief summary of what it represents.  For example, I used the following for the test, though with a lot more blank space that you probably shouldn't use unless you carefully explain to cUrl that you have a multi-line string.

```
curl http://media-server.local:11434/api/generate -d '
{
  "model": "llama3.2:1b",
  "prompt": "Extract all proper nouns from the Markdown
             text below, identifying what each represents.
             Return a single JSON object only, no
             explanation and no extra text. Use the
             following schema:
             {
               nouns: [
                 {
                   name: [string],
                   description: [string]
                 }
               ]
             }
             The text follows.
             ---
             ...
            "
}'
```

It didn't do a great job on the summaries, which I expected, but it actually did the job, which I did *not* expect.  And it didn't try to "engage" me by doing a bad job, trying to find related tasks, and the like.  Likewise, I gave it a chapter of Louisa May Alcott to read to list what it revealed about the character that it introduces[^2].

[^2]:  I often have questions like this when the character has some second-hand reputation, such as claims of some interesting trait or the author basing them on a famous now-historical figure, that *would* make them suitable for a future project.  For an unrelated example, Twain and Warner allegedly based many side characters in [**The Gilded Age: A Tale of Today**](https://en.wikipedia.org/wiki/The_Gilded_Age:_A_Tale_of_Today) on contemporary politicians, making them potentially valuable for certain kinds of projects.  But for a lesser author than Mark Twain, does anybody want to commit to six hundred pages *in case* Senator Abner Dilworthy seems interesting when (and if, since you can find plenty of incorrect reporting on older books) he shows up?

Oh, one more potential use, the one that actually convinced me to install something.  As some of you know, I still *hunt the wild job*, if you'll pardon the drama.  In my first run, I started with lists of websites of companies known for remote work, then tediously worked through each one.  And during the process, it frequently occurred to me that it would have saved quite a bit of time to have software handle a lot of this.  Consider the following for each URL.

- Pull the webpage.
- If the page doesn't exist, give up.
- Search the page for the link that might mean a list of jobs, such as careers, join our team, and so forth.
- If we have no such link, give up.
- Pull the page of the jobs link.
- Extract a list of jobs that sound like my area, senior software engineer, software engineering manager, technical lead, and so on.
- For each potential result, compare the page's requirements with my requirements, giving them a score.

Several of those steps---finding the jobs, filtering out the unlikely matches, and comparing the job descriptions with what I want and do---would work best with LLMs, given the vagueness and flexibility of the requirements, whereas the rest only need a programming language that can make HTTP calls.  And with a tool like this, I could skip past the abandoned websites, the totally remote jobs that only require candidates to live within twenty yards of the North Pole (magnetic, not geographic) and come into the office four days per week, entry-level positions, military contracting, and the like.

### Results

In all those cases, I'd never *publish* that output, because it doesn't have much practical use apart from maybe helping me focus my reading or other work.  But I see that as potentially useful, and extraordinarily difficult to do manually or algorithmically...or with a chatbot.  Likewise, I haven't tested it, but I *suspect* that it might have some value when I keep notes on my ideas or my nightly journal entries, in that I could plausibly submit sections and have it ask some small number of questions where I might want to follow up on or clarify.

I should note that the process does take a while, and it returns its answers in blocks of three-to-four characters, each embedded in a JSON object, such as this.

```JSON
{
  "model": "llama3.2:1b",
  "created_at": "[Timestamp]",
  "response": "{ \"",
  "done": false
}
```

I assume that it does this for the inane "let me type this slowly to waste as much of your time as possible" shtick that pretends that it "thinks" really hard about your problem.

Anyway, the last of these entries sets `done` to true with a reason such as `stop`, followed by a `context` array of numbers, and some metrics on the prompt and execution.  In other words, it takes some minor processing of the results, extracting every `response` element and joining into a single string.  But this feels like exactly the right role for LLMs in my life, taking care of small tasks that I would find tedious to do myself and don't have a more efficient solution available, with no "Genuine People Personalities" nonsense, and no asking it to generate anything that'll only disappoint anyway.

It'll need some client-side work to make it usable, but I can do that in the narrow cases where it might help.

And if anybody releases a small enough [Common Pile](https://huggingface.co/common-pile) model, that similarly has some potential for improving the situation.

## Ham Newsletter

{% codeberg jcolag/ham-newsletter %}

I copied the repository over to Codeberg, but didn't have anything more to do with it, this time around.

Actually, I *did* add a script for my own use, but it more properly belongs to the blog rather than the newsletter, since I use it to streamline the [Social Media Roundup](/blog/tag/link-dump) posts.  It adapts the existing script to get the saved articles from Fresh RSS, but instead of getting all articles for the previous month, it grabs those from Monday through Friday, so that I can pick them off faster for my post than clicking through on Fresh RSS itself.

I could probably enhance it by having it pull out the header images and any captions or existing alt-text, but that feels like it'd create too much noise, since I generally mark about fifty articles as interesting enough to revisit, and usually no more than eight ever end up in a Friday post.

## Entropy Arbitrage

{% codeberg jcolag/entropy-arbitrage-code %}

The blog's code has arrived on Codeberg.

The default page layout also received a quick update to---down before the list of tags, if you haven't noticed it before---point to the Markdown source of that post on Codeberg instead of the version on GitHub.

## Ham Newsletter

{% codeberg jcolag/ham-newsletter %}

Similarly, the scripts to generate and send the newsletter---out on Saturday for those of you subscribed on Mailchimp[^3], and tomorrow morning for those of you taking the [Buy Me a Coffee](https://buymeacoffee.com/jcolag) route---also now live on Codeberg.

[^3]:  I have almost three hundred subscribers, somehow, ironically not picking up from single-digits until *after* trying to direct people to the other outlet.  I assume that most of the sign-ups come from bots, but if any humans live in the pile, I hope that I've made it interesting, at least...

And to go with the transition, the Fresh RSS script needed a quick patch, because it somehow got out, and used last month without issue, with an undefined variable that it needed.  Oh, and I also needed to bump a library version over on GitHub, so that has made it over here, too, one of the nicer things about using git...

## Boring CSS

{% codeberg jcolag/boring-css %}

Add another to the pile migrated over to Codeberg.  This time, you don't get a story of some small patch padding out this section.  But it does feel like one of the projects most likely to see updates over time.

## Bicker

{% codeberg jcolag/Bicker %}

Like **Boring CSS**, I moved this to Codeberg without needing to make any changes, but I *might* revisit it in the future.

## Open Badges

{% codeberg jcolag/badging %}

Another project that now lives on Codeberg, because I expect to return to it at some point.  This also feels like the project most likely to require some interaction back on GitHub, because I really should reach out to the people maintaining the test code to ask how to get it running, these days.

## Mastodon Tool Trunk

{% codeberg jcolag/tool-trunk %}

And one final project for the week that lives on Codeberg, because I use it regularly enough to warrant keeping the repository in front of me.

## Next

I would expect more of the same, this week, copying projects with decent chances of getting an update over to Codeberg.

* * *

**Credits**:  The header image is [Fountain pen writing](https://commons.wikimedia.org/w/index.php?curid=55607334) by [Petar Milošević](https://commons.wikimedia.org/wiki/User:PetarM), made available under the terms of the [Creative Commons Attribution Share-Alike 4.0 International](https://creativecommons.org/licenses/by-sa/4.0/deed.en) license.
