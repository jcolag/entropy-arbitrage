---
layout: post
title: Developer Diary, World Elephant Day
date: 2024-08-12 08:00:05-0400
categories:
tags: [programming, project, devjournal]
summary: Progress on assorted projects
thumbnail: /blog/assets/Kissing_Elephants.png
offset: -15%
teaser: This week's projects include updating blog posts, a massive update and improvement to the blog's code, and Fictopedia.  A toy got bumped in all the excitement...
spell: Fictopedia Kabang OpenMoji Twemoji gucharmap Noto avifenc yuv aom _eassets tsfile fi newermt basename dest avif cp extname gsub img woohoo
proofed: true
---

* Ignore for ToC
{:toc}

Today, we celebrate [World Elephant Day](https://en.wikipedia.org/wiki/World_Elephant_Day) and [International Youth Day](https://en.wikipedia.org/wiki/International_Youth_Day), both of which seem sufficiently self-descriptive that I'll maybe recommend that you double up, today, and hug a young elephant or something.

![Elephants sharing water](/blog/assets/Kissing_Elephants.png "Setting a boundary now, in case it ever comes up:  No matter how dehydrated I get, you do not have permission to stuff your nose in my mouth...")

Probably less useful, but feeling more in my wheelhouse, tomorrow also marks [Jenny Everywhere Day](https://www.jennyeverywhereday.com/).  I vented about [my problems with the character]({% post_url 2024-08-11-open-source-characters %}) yesterday[^1], so I won't bother you with those problems again.

[^1]:  That post actually started out as a footnote exactly like this one, but kept growing...

Therefore, on we go to the projects.

## Entropy Arbitrage, the Posts

{% github jcolag/entropy-arbitrage %}

As I've mentioned, I *finally* churned through the remaining old posts.  Every one of them should now have a table of contents---assuming that the post has any subheadings at all---as far back as the [first post on the blog]({% post_url 2019-12-08-greetings %}).

As we go further back in the index, such as in that first post, you'll see that I made some "interesting" semantic choices that don't work well together.  For example, I spent a couple of years using sixth-level headings (`######`) as citations for quotes, before creating a tag to handle that more cleanly.  But I'd rather expose those problems, and maybe one day in the far future fix them, than not extend conveniences that I should have learned about and used from the start.

I also went back and fixed some posts after I started automating the process, and it got a bit over-zealous, adding sometimes as many as three bogus---or *bonus*, I suppose, if you enjoy them---tags for tables of contents.

## Entropy Arbitrage, the Code

{% github jcolag/entropy-arbitrage-code %}

Oh, boy.  Strap in, everyone.  I might have gone the *tiniest* bit overboard.  I haven't even committed a bunch of what went out, yet, because I still want to run some additional tests.

This discussion might go on for a while, so I'll try to break it up with subheadings of its own, so that interested parties can find the parts that interest them later.  If you want to start skimming until you get to the parts about readable material, you won't hurt my feelings.

To summarize for those about to skim, we have more link icons, we have programming language icons, and loading pages into your browser should now happen significantly faster.  I didn't have the time to commit the code-based icons, so you'll need to wait until next week to hear about them, even though you'll get the benefit of them already.

### Link Icons, Continued

Picking up where I left off [last week]({% post_url 2024-08-05-coast-guard %}), I added the [Simple Icons](https://simpleicons.org/) font and added a *bunch* of icons for outbound links, ranging from frequent "guests" [Buy Me a Coffee](https://www.buymeacoffee.com/jcolag) and the [Internet Archive](https://archive.org) to rarer appearances such as...well, Simple Icons itself, earlier in this paragraph.  As I hope that I mentioned last week, the icons grow when you hover over them, to make the destination clearer as you get closer to clicking the link.

If you ever need to do something like this, I pulled all the URLs used by the blog with the following command.

```console
grep -or 'http[^)>]*' _posts/*.md | \
  cut -f2- -d':' | \
  grep -v '\.jpg' | \
  grep -v '\.png' | \
  cut -f3 -d'/' 
```

In other words, find all strings that look like they might start a URL, hack off the filename, skip anything pointing to an off-site image, and (finally) grab the piece of the URL between the protocol and the path.  As I added common domain patters to the CSS, I applied another `| grep -v whatever-site.example` command to remove it and its subdomains from the list.  It has some imperfections, but does a good-enough job for a one-time project.  And then, for everything that seemed frequent enough on the blog or likely to increase in frequency in the future, I checked `simpleicons.css`---which I don't use otherwise---to see if they had an icon listed, and what Unicode code-point they assigned to the character.

As an aside, because I mixed up the fonts in one of the rules and couldn't get the correct icon to show up, I looked for alternate ways to find the correct code-point, and discovered the modern GNOME character map (`gucharmap`), which---presumably to nobody's surprise but my own---allows you to pick a font, select a Unicode section, and look through a grid of the characters.  In the case of icon fonts like Font Awesome, Simple Icons, or the newly released [Distributed Social Icons](https://codeberg.org/WeDistribute/decentralized-social-icons), you want the "Unknown" section, as in not defined by the Unicode Consortium.

#### Legal Talk, Quickly

However, I should note that these little link annotations do introduce a *small* instability to the blog.  Even though the fonts that I use have free licenses, the icons have copyrights and trademarks owned by the individual organizations that they represent.  This comes as close to clear-cut [nominative fair use](https://en.wikipedia.org/wiki/Nominative_use) as I think you could reasonably get, using a logo to identify the source of a link, *but* everybody reading this probably knows that I don't trust anything resembling fair use, because it requires getting sued and explaining everything to a judge to make a real decision.

It almost certainly won't come to that, but I still wanted to make it clear that I spent time weighing my distrust of Fair Use with the value to readers.  If anybody from one of the organizations in question asks me to stop using their icon, I'll make do with the generic off-site-link icon.

### (Much) Smaller Images

Last week, when suggesting that I might add those code icons from the previous section, I also said...

 > I may also consider one other major change to the blog, especially now that I've started thinking about performance and only now realized that I have probably ignored the most significant aspect of that, on a per-post basis.  But I want to make sure that, if I do so, I don't end up making much more busywork for myself.

While I shaded the language to avoid making promises that I couldn't keep, I meant the images embedded in pages.  Ignoring the emoji font at the largest and the smattering of small images, pictures on the blog have tended to run from around 100 kB to 3.8 MB.  By contrast, the largest posts top out at around 150 kB[^3], larger than the smallest images, but not by much, and a median post hits 40 kB.

[^3]:  That actually didn't hold true until recently, unfortunately, due to some sloppy coding on my part.  I'll talk about that after finishing with the images.

In other words, ignoring the aforementioned emoji font---which I should probably reconsider now that I know the numbers[^5], sure---when you open a post here, you have spent most of your time waiting for the images to load, except for *extremely* long posts that happen to also have a low-complexity header image.  As a result, instead of worrying about adding Simple Icons, whether as icons or the full font, I should have spent more time worrying about how to shrink the images.

[^5]:  Google's Noto Color Emoji came in at a whopping 23 MB for the version that I had, somehow shrunk to 11 MB for the version released at the end of 2023, which yes, I updated to that version.  OpenMoji comes in at about the same (newer) size.  Nobody has updated Twemoji in a long time, and looking through the issues shows that [&#x1D54F; laid off the developer in charge of the Unicode 15.0 release](https://github.com/twitter/twemoji/issues/570) before they released it, so I have to take that font off the table.  Nobody has touched the open source version of EmojiOne in years, also removing it from consideration.  Do any other open source emoji fonts exist?

And oh, look, we already have a solution for this.  The [AV1 Image File Format](https://en.wikipedia.org/wiki/AVIF) (AVIF) generally shows much better compression with better detail preservation and fewer compression artifacts.  In other words, we fit more of the same image in a smaller space.  I ran a quick test on the blog's assets directory, converting all images that I could (PNG and JPEG) from their original format into AVIF files.

```console
avifenc --min 30 --max 63 --speed 0 --yuv 420 -d 8 --codec aom "${file}" "${file}.avif"
```

And the results seemed...well, fairly compelling.  While I didn't inspect every image, because *nobody* has that kind of time, a random sampling didn't show any significant visual differences from the originals.  And as important, whereas I previously deployed 544 MB of assets[^6] to the server, the same assets now clock in at 76 MB, or about fourteen percent of the original size where, on average, you probably won't notice a difference in quality.

[^6]:  The assets include all the images, fonts, stylesheets, and one-off items like audio clips, PDF files, and [**Kabang!**]({% post_url 2023-08-13-kabang %}).

I have complained about AVIF images before, in posts such as [*Normalizing Image Type and Size*]({% post_url 2023-04-05-file-type-size %}), because social media and native tools haven't caught up with the widespread new formats as input, but I now see how they became so widespread, and follow suit.

#### Source versus Deployment

I should note that, for a variety of reasons, I won't change what goes into the [**Entropy Arbitrage** assets](https://gitlab.com/jcolag/entropy-arbitrage-assets) repository.  That will continue to house the same (mostly PNG) images, whereas I probably won't store the AVIF versions anywhere permanent, since anybody can get at them with the command above.

If you do spot an image that conversions have turned to garbage, then, please contact me, since it only means that I'll need to fuss with that specific conversion manually, trying different minimum and maximum values for quality.  The "original"---the version that I otherwise set up for the blog or would have---stays close at hand, in addition to the original version of *that* image linked from its post and the `LICENSE.md` monstrosity.

Instead of permanently converting everything that I can to AVIF files, I wrote a script to do the difficult parts for me, which I present in case somebody needs something similar.

```bash
#!/usr/bin/bash
from=_eassets
to=assets
tsfile=.assets-latest
last=$(date --date=@0)
if [ -f .assets-latest ]
then
  old=$(cat "${tsfile}")
  last=$(date --date=@"${old}")
fi
find "${from}" -newermt "${last}" -not -path "${from}/.git/*" -type f -print | while read -r file
do
  base=$(basename "${file}")
  dest="${to}/${base}.avif"
  avifenc --min 30 --max 63 --speed 0 --yuv 420 -d 8 --codec aom "${file}" "${dest}"
  if [ $? == 1 ]
  then
    cp "${from}/${base}" "${to}"
  fi
done
date +%s > "${tsfile}"
```

It doesn't do anything complex, so pardon the lack of comments.  It checks a hidden file for a time-stamp from the last time I ran the script---a default of time-stamp zero, without the previous run---and finds all (non-overhead) files newer than that time.  For each of them, we try to convert the file to AVIF, and if the conversion fails (`$? == 1`), it probably happened for having the wrong format, so copy the file instead.  And then it ends by creating or overwriting the time-stamp.

#### Oh, No, Not Again...

However, doing everything this way presents a problem:  I now have images that the posts don't point to.  I finally finished going through to manually add table-of-contents code into every one of over a thousand posts.  And as I quoted myself writing, I *don't* want this process to make more busy-work for myself.  I won't put myself through that again, at least not in the near future for the blog posts.  Nobody wants to read week after week of me scraping through Markdown files appending `.avif` to image targets.

Pleasantly enough, Jekyll has most of a solution to this problem, pre-render hooks, which allow the blog to alter the Markdown before anybody else touches it[^4], without touching the file.  In my case, it looks like the following.

[^4]:  Yep, I almost certainly could've used the same feature to insert the Tables of Contents on every page, instead of altering every single post.  Live and learn, I guess.  But this also does raise the question of, if Jekyll has all the pieces to do this, why I couldn't turn a flag on in the configuration to get the tables, instead of doing *any* real work...

```ruby
Jekyll::Hooks.register [:posts, :pages], :pre_render do |doc|
  if doc.extname == '.md' || doc.extname == '.markdown'
    # For each Markdown image...
    doc.content = doc.content.gsub(/!\[([^\]]*)\]\(([^ )]+)(?:\s+"([^"]*)")?\)/) do |match|
      # Grab the alt-text, URL, and title-text.
      alt_text = Regexp.last_match 1
      src = Regexp.last_match 2
      title_text = Regexp.last_match 3

      # Figure out the equivalent AVIF file.
      avif_src = src + '.avif'
      avif_path = avif_src.sub /^\/blog/, '_site'

      # Replace the URL with the AVIF equivalent if (and only if) the file exists.
      if File.exist? avif_path
        "![#{alt_text}](#{avif_src} \"#{title_text}\")"
      else
        match
      end
    end
  end
end
```

Note that finding the AVIF file's path should do something more sophisticated in the second line, to make it portable for people who don't contain their blogs in separate folders or where that target has a different path.  Regardless of minor improvements to make later, if `avifenc` converted the file, this rewrites images in posts to point at whatever version that we happen to have.  

However, this change only deals with the post itself, and does *not* update the images used on the index page, the faded-out strip of the header image that I use to give a small hint about the contents of the post.  I tried to handle the index there, but it would only ever fix the image for the most recent post saved.  To fix that, I won't bother digging into the full code---showing Liquid templates in a Jekyll post always causes problems, because the rendering insists on always expanding them---but in short, I let SVG and GIF images slip through in the traditional `img` tag, but for everything else, add an AVIF extension for something like this, if you imagine some curly braces thrown in where you see extra spaces.

```HTML
<picture>
  <source
    srcset=" thumbnail_with_dot_avif "
    style="margin-top:  offset ;"
  >
  <img
    src=" post.thumbnail "
    style="margin-top:  offset ;"
  >
</picture>
```

By using the [`picture` element](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture), it should always pick the best match.  That means that, if I need to revert to the old images at some point, I shouldn't need to undo anything here, beyond swapping in the original assets folder, because I still have the original file named in the element.  At least, the theory tells me that should happen.

### Vast Emptiness

I bent the truth a bit, when I talked about the relative sizes of things, above.  I mentioned that the *really* big posts might grow as large as 150 kB, because that really only holds true *now*.  When I collected data for this post, I checked the size of the largest posts, and noticed that---maybe including some of these changes---a relatively short post like the [Free Culture News]({% post_url 2024-06-09-free-culture-news %}) "prototype" post (1,600 words, give or take), grew to almost **half a megabyte**.

That didn't make any sense, unless I started using three-hundred-letter words without anybody complaining, so I started investigating.  And I found...spaces.  I found thousands of lines of space characters.  Every few hundred lines, I'd find one of those "past/future part of the conversation" links that I've added over the years, which gave me a clue:  This code runs in loops, one of which runs across all posts on the blog, and the different line lengths looked like indentation for HTML that didn't exist.

I looked for coding solutions to collapse this space after-the-fact, with a surprising number of people having strong recommendations---usually some level of pre-processing---that don't do anything.  And then I found somebody referring to [Liquid's spacing control](https://shopify.github.io/liquid/basics/whitespace/), where I add hyphens to suppress the spaces that pour out of empty loops.  Honestly, I shouldn't need to do this, because those extra spaces produce no legitimate effect, since HTML collapses all runs of spaces into a single space, always and without fail, and therefore no product generating HTML should produce extra space.  But they set it up this way, and so I need to deal with it.

The aforementioned news post now only takes up 44 kB, less than one-tenth its prior size, which should make reading here less onerous for people. {% emoji woohoo %}

## Fictopedia Archive

{% codeberg jcolag/fictopedia %}

I have *finally* made my way through every Fictopedia page, fixing the links, including the category and user pages, and---I believe---all the wiki-specific links.  I also caught some typographical errors along the way, such as occasionally showing `%27` instead of an apostrophe.

The category pages have everything that they'll likely get.  All the user pages have as much content as they seem likely to get.  I don't believe that I have any other changes that I can spot.

As I said last time, though, if anybody out there has pages that I don't, wants to clean up more than I have, or can figure out the font in the logo, I have no objection to improving this archive further.

## Next

As mentioned, I still have some code for the blog to finish testing before I commit, so expect to see a lot of that, next week, as well as probably discovering a whole raft of errors in the link annotation icons.  I'd like to say that I won't need to touch Fictopedia any time soon, but I don't know if I can make that promise, but I will commit to saying that next week will have an update for **The Light's Edge** that will probably at least amuse somebody, kicking off a new repository soon.

* * *

**Credits**:  The header image is [Kissing Elephants](https://commons.wikimedia.org/wiki/File:Kissing_Elephants.JPG) by [Nicolas M. Perrault](https://commons.wikimedia.org/wiki/User:Nicolas_Perrault_III), made available under the terms of the [Creative Commons CC0 1.0 Universal Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/deed.en).
